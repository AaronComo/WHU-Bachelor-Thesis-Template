% Encoding: UTF-8

@article{汪润2018sprd,
    title={SPRD: 基于应用 UI 和程序依赖图的 Android 重打包应用快速检测方法},
    author={汪润 and 王丽娜 and 唐奔宵 and 赵磊},
    journal={Journal on Communications},
    year={2018}
}
@article{Liang_Liu_Wang_Wu_Li_Zhang_Wang_Yang_2025, 
    title={Transfer Learning of Real Image Features with Soft Contrastive Loss for Fake Image Detection}, 
    volume={39}, 
    url={https://ojs.aaai.org/index.php/AAAI/article/view/34826}, 
    DOI={10.1609/aaai.v39i25.34826}, 
    abstractNote={In the last few years, the artifact patterns in fake images synthesized by different generative models have been inconsistent, leading to the failure of previous research that relied on spotting subtle differences between real and fake. In our preliminary experiments, we find that the artifacts in fake images always change with the development of the generative model, while natural images exhibit stable statistical properties. In this paper, we employ natural traces shared only by real images as an additional target for a classifier. Specifically, we introduce a self-supervised feature mapping process for natural trace extraction and develop a transfer learning based on soft contrastive loss to bring them closer to real images and further away from fake ones. This motivates the detector to make decisions based on the proximity of images to the natural traces. To conduct a comprehensive experiment, we built a high-quality and diverse dataset that includes generative models comprising GANs and diffusion models, to evaluate the effectiveness in generalizing unknown forgery techniques and robustness in surviving different transformations. Experimental results show that our proposed method gives 96.2% mAP significantly outperforms the baselines. Extensive experiments conducted on the widely recognized platform Midjourney reveal that our proposed method achieves an accuracy exceeding 78.4%, underscoring its practicality for real-world application deployment.}, 
    number={25}, 
    journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
    author={Liang, Ziyou and Liu, Weifeng and Wang, Run and Wu, Mengjie and Li, Boheng and Zhang, Yuyang and Wang, Lina and Yang, Xinyi}, 
    year={2025}, 
    month={Apr.}, 
    pages={26281-26289} 
}

@inproceedings{liu2024lips,
    author = {Liu, Weifeng and She, Tianyi and Liu, Jiawei and Li, Boheng and Yao, Dongyu and Liang, Ziyou and Wang, Run},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {A. Globerson and L. Mackey and D. Belgrave and A. Fan and U. Paquet and J. Tomczak and C. Zhang},
    pages = {91131--91155},
    publisher = {Curran Associates, Inc.},
    title = {Lips Are Lying: Spotting the Temporal Inconsistency between Audio and Visual in Lip-Syncing DeepFakes},
    url = {https://proceedings.neurips.cc/paper_files/paper/2024/file/a5a5b0ff87c59172a13342d428b1e033-Paper-Conference.pdf},
    volume = {37},
    year = {2024}
}